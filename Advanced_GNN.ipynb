{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "567634b4",
      "metadata": {
        "id": "567634b4"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RichardJPovinelli/Neural_Networks_Course/blob/main/Advanced_GNN.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jejlWCxtSBc"
      },
      "source": [
        "# 1. Overview\n",
        "Compare GIN, GraphSAGE, and GAT; pooling; over-smoothing demo.\n",
        "\n",
        "**TODO:**\n",
        "- Read the notebook top to bottom once to understand the flow.\n",
        "- Ensure dependencies are installed and kernel is ready. (Suggested: use the included `install_pyg_gpu_cu118.ps1` script if on Windows with GPU.)\n",
        "- Run the dataset-loading cell and inspect dataset summaries."
      ],
      "id": "2jejlWCxtSBc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b632619d",
      "metadata": {
        "id": "b632619d",
        "outputId": "74d76214-ad2c-408d-c2b7-7d60364f6271",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected Google Colab environment — ensuring required packages are installed...\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-spline-conv\n",
            "  Downloading torch_spline_conv-1.2.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.10.5)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-scatter, torch-sparse, torch-cluster, torch-spline-conv\n"
          ]
        }
      ],
      "source": [
        "# Colab helper: install wheel dependencies if running in Google Colab\n",
        "\n",
        "\n",
        "import sys, subprocess, importlib\n",
        "\n",
        "\n",
        "# Try to detect if we're running inside Google Colab\n",
        "try:\n",
        "    import google.colab  # type: ignore\n",
        "    print(\"Detected Google Colab environment — ensuring required packages are installed...\")\n",
        "    # Check for required modules; if missing, we'll pip install appropriate packages\n",
        "    %pip install torch torchvision torchaudio torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
        "    print(\"Colab dependency installation completed — import cells can now run.\")\n",
        "except Exception:\n",
        "    print(\"Not running inside Google Colab — assuming local environment has required packages.\")\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, GINConv, global_mean_pool\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqFe1cBntSBe"
      },
      "source": [
        "## 2. Load Datasets\n"
      ],
      "id": "CqFe1cBntSBe"
    },
    {
      "cell_type": "markdown",
      "id": "05ebe281",
      "metadata": {
        "id": "05ebe281"
      },
      "source": [
        "### Transductive Benchmark Datasets\n",
        "- **Cora:** 2,708 machine-learning papers; 7 classes; 1,433 sparse word-frequency features; 5,429 citation edges.\n",
        "- **CiteSeer:** 3,327 research publications; 6 topic labels; 3,703 binary word features; 4,732 citation links.\n",
        "- **PubMed:** 19,717 biomedical articles; 3 disease classes; 500 TF-IDF features; 44,338 citation pairs.\n",
        "\n",
        "All three share the standard Planetoid splits with 20 training nodes per class, 500 validation nodes, and 1,000 test nodes to facilitate direct model comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA9e47MMtSBf"
      },
      "outputs": [],
      "source": [
        "datasets = {}\n",
        "for name in [\"Cora\", \"CiteSeer\", \"PubMed\"]:\n",
        "    datasets[name] = Planetoid(root=f\"./{name}\", name=name)  # store the dataset object (not dataset[0])\n",
        "\n",
        "print({name: (ds[0].num_nodes, ds[0].num_edges, ds.num_node_features, ds.num_classes) for name, ds in datasets.items()})\n"
      ],
      "id": "YA9e47MMtSBf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHQJtp_StSBf"
      },
      "source": [
        "## 3. Define Models\n",
        "\n",
        "This section defines model classes and the math behind the architectures."
      ],
      "id": "zHQJtp_StSBf"
    },
    {
      "cell_type": "markdown",
      "id": "cbd709b8",
      "metadata": {
        "id": "cbd709b8"
      },
      "source": [
        "### 3.1 GraphSAGE: Equations & Intuition\n",
        "- **Neighborhood sampling:** $S_v^{(k)} = \\text{Sample}(\\mathcal{N}(v), K)$\n",
        "- **Mean aggregator:** $\\text{AGG}^{(k)}(v) = \\frac{1}{|S_v^{(k)}|} \\sum\\limits_{u \\in S_v^{(k)}} h_u^{(k)}$\n",
        "- **Pooling aggregator:** $\\text{AGG}^{(k)}(v) = \\max\\limits_{u\\in S_v^{(k)}} \\sigma\\!\\left(W_\\text{pool}^{(k)} h_u^{(k)} + b\\right)$\n",
        "- **Node update:** $h_v^{(k+1)} = \\sigma\\!\\left(W^{(k)} \\cdot [h_v^{(k)} \\Vert \\text{AGG}^{(k)}(v)]\\right)$\n",
        "\n",
        "**TODO:**\n",
        "- Try the mean and pooling aggregators and compare the learned embeddings for a tracked node.\n",
        "- Visualize neighbor sets and their embeddings for a chosen node."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fffddb28",
      "metadata": {
        "id": "fffddb28"
      },
      "source": [
        "### 3.2 GraphSAGE Internals Walkthrough\n",
        "The cells below implement a \"verbose\" GraphSAGE layer that explicitly shows neighborhood sampling, mean aggregation, optional max-pooling, and the node update step so you can trace each intermediate tensor.\n",
        "\n",
        "**TODO:**\n",
        "- Run the verbose inspector for different `node_id` and `sample_size` values and note how aggregators change.\n",
        "- Modify the `GraphSAGEVerboseLayer` to compute both mean and pooling at once and compare outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41dfb3c1",
      "metadata": {
        "id": "41dfb3c1"
      },
      "outputs": [],
      "source": [
        "class GraphSAGEVerboseLayer(nn.Module):\n",
        "    \"\"\"Pedagogical layer that surfaces each GraphSAGE sub-step.\"\"\"\n",
        "    def __init__(self, in_ch: int, hid: int):\n",
        "        super().__init__()\n",
        "        self.self_linear = nn.Linear(in_ch, hid)\n",
        "        self.aggregate_linear = nn.Linear(in_ch, hid)\n",
        "        self.update_linear = nn.Linear(2 * hid, hid)\n",
        "        self.pool_linear = nn.Linear(in_ch, hid)\n",
        "    def forward(self, data, node_id: int, sample_size: int = 5):\n",
        "        edge_index = data.edge_index\n",
        "        src, dst = edge_index\n",
        "        all_neighbors = torch.unique(src[dst == node_id])\n",
        "        debug = {\n",
        "            \"neighbors\": all_neighbors.tolist() if all_neighbors.numel() > 0 else []\n",
        "        }\n",
        "        if all_neighbors.numel() == 0:\n",
        "            sampled = all_neighbors\n",
        "        elif sample_size is None or all_neighbors.numel() <= sample_size:\n",
        "            sampled = all_neighbors\n",
        "        else:\n",
        "            perm = torch.randperm(all_neighbors.numel())[:sample_size]\n",
        "            sampled = all_neighbors[perm]\n",
        "        debug[\"sampled_neighbors\"] = sampled.tolist() if sampled.numel() > 0 else []\n",
        "        if sampled.numel() == 0:\n",
        "            sampled_feats = data.x.new_zeros((1, data.x.size(1)))\n",
        "        else:\n",
        "            sampled_feats = data.x[sampled]\n",
        "        mean_raw = sampled_feats.mean(dim=0)\n",
        "        pool_proj = torch.relu(self.pool_linear(sampled_feats))\n",
        "        pool_hidden = pool_proj.max(dim=0).values\n",
        "        self_part = self.self_linear(data.x[node_id])\n",
        "        mean_hidden = self.aggregate_linear(mean_raw)\n",
        "        concat = torch.cat([self_part, mean_hidden], dim=0)\n",
        "        updated = torch.relu(self.update_linear(concat))\n",
        "        debug.update({\n",
        "            \"mean_raw\": mean_raw.detach().cpu(),\n",
        "            \"mean_hidden\": mean_hidden.detach().cpu(),\n",
        "            \"pool_hidden\": pool_hidden.detach().cpu(),\n",
        "            \"concat\": concat.detach().cpu(),\n",
        "            \"updated\": updated.detach().cpu()\n",
        "        })\n",
        "        return updated, debug\n",
        "\n",
        "def show_graphsage_internals(ds_name: str = \"Cora\", node_id: int = 42, sample_size: int = 5, seed: int = 0):\n",
        "    torch.manual_seed(seed)\n",
        "    dataset = datasets[ds_name]  # Planetoid dataset object\n",
        "    data = dataset[0]  # Data object from dataset\n",
        "    layer = GraphSAGEVerboseLayer(data.num_node_features, 32)\n",
        "    updated, info = layer(data, node_id=node_id, sample_size=sample_size)\n",
        "    print(f\"Dataset: {ds_name}\")\n",
        "    print(f\"Target node: {node_id}\")\n",
        "    print(f\"Neighbors ({len(info['neighbors'])}): {info['neighbors']}\")\n",
        "    print(f\"Sampled ({len(info['sampled_neighbors'])}): {info['sampled_neighbors']}\")\n",
        "    mean_preview = [round(v, 4) for v in info[\"mean_raw\"][:5].tolist()]\n",
        "    pool_preview = [round(v, 4) for v in info[\"pool_hidden\"][:5].tolist()]\n",
        "    updated_preview = [round(v, 4) for v in info[\"updated\"][:5].tolist()]\n",
        "    print(f\"Mean aggregator (first 5 dims): {mean_preview}\")\n",
        "    print(f\"Pooling aggregator (first 5 dims): {pool_preview}\")\n",
        "    print(f\"Updated embedding (first 5 dims): {updated_preview}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22e088a4",
      "metadata": {
        "id": "22e088a4"
      },
      "outputs": [],
      "source": [
        "# Example inspection: adjust node_id/sample_size to explore other neighborhoods\n",
        "show_graphsage_internals(ds_name=\"Cora\", node_id=42, sample_size=6, seed=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7429aba2",
      "metadata": {
        "id": "7429aba2"
      },
      "source": [
        "### 3.3 GAT: Equations & Intuition\n",
        "- **Linear projection:** $h'_{i} = W h_{i}$\n",
        "- **Attention logits:** $e_{ij} = \\text{LeakyReLU}\\!\\left(a^{\\top}[h'_i \\Vert h'_j]\\right)$ for $j \\in \\mathcal{N}(i)$\n",
        "- **Normalized coefficients:** $\\alpha_{ij} = \\text{softmax}_j(e_{ij}) = \\frac{\\exp(e_{ij})}{\\sum\\limits_{k \\in \\mathcal{N}(i)} \\exp(e_{ik})}$\n",
        "- **Neighborhood aggregation:** $h^{(k+1)}_{i} = \\sigma\\!\\left(\\sum\\limits_{j \\in \\mathcal{N}(i)} \\alpha_{ij} h'_j\\right)$\n",
        "- **Multi-head fusion:** $h^{(k+1)}_{i} = \\Vert_{m=1}^{M} \\sigma\\!\\left(\\sum\\limits_{j \\in \\mathcal{N}(i)} \\alpha^{(m)}_{ij} h'^{(m)}_j\\right)$\n",
        "\n",
        "**TODO (students):**\n",
        "- Run the GAT verbose cell and inspect per-head attention coefficients for a chosen node.\n",
        "- Compare attention distributions across heads and neighbors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "986460a2",
      "metadata": {
        "id": "986460a2"
      },
      "source": [
        "### 3.4 GAT Internals Walkthrough\n",
        "This section implements a \"verbose\" GAT layer that exposes the linear projections, attention logits, normalized coefficients, and the per-head neighborhood aggregation for a single node so students can trace the full attention computation step-by-step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c01ea53",
      "metadata": {
        "id": "6c01ea53"
      },
      "outputs": [],
      "source": [
        "class GATVerboseLayer(nn.Module):\n",
        "    \"\"\"Pedagogical GAT layer that shows per-head attention computations for a single node.\"\"\"\n",
        "    def __init__(self, in_ch:int, out_ch:int, heads:int=4, leaky_slope:float=0.2):\n",
        "        super().__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.out_ch = out_ch\n",
        "        self.heads = heads\n",
        "        self.leaky_slope = leaky_slope\n",
        "        # linear projection per head (no bias)\n",
        "        self.projs = nn.ModuleList([nn.Linear(in_ch, out_ch, bias=False) for _ in range(heads)])\n",
        "        # attention linear per head: maps concatenated [Wh_i || Wh_j] to a score\n",
        "        self.attn = nn.ModuleList([nn.Linear(2 * out_ch, 1, bias=False) for _ in range(heads)])\n",
        "    def forward(self, data, node_id:int, sample_size:int=None, return_per_head=False):\n",
        "        edge_index = data.edge_index\n",
        "        src, dst = edge_index\n",
        "        all_neighbors = torch.unique(src[dst == node_id])\n",
        "        info = {\n",
        "            'neighbors': all_neighbors.tolist() if all_neighbors.numel() > 0 else []\n",
        "        }\n",
        "        # sample neighbors for pedagogy if requested (none -> all)\n",
        "        if all_neighbors.numel() == 0:\n",
        "            sampled = all_neighbors\n",
        "        elif sample_size is None or all_neighbors.numel() <= sample_size:\n",
        "            sampled = all_neighbors\n",
        "        else:\n",
        "            idx = torch.randperm(all_neighbors.numel())[:sample_size]\n",
        "            sampled = all_neighbors[idx]\n",
        "        info['sampled_neighbors'] = sampled.tolist() if sampled.numel() > 0 else []\n",
        "        # Project features for all nodes for each head\n",
        "        projections = []\n",
        "        for h in range(self.heads):\n",
        "            projections.append(self.projs[h](data.x))  # (N, out_ch) per head\n",
        "        head_outputs = []\n",
        "        head_info = []\n",
        "        for h in range(self.heads):\n",
        "            proj = projections[h]\n",
        "            if sampled.numel() == 0:\n",
        "                # no neighbors: aggregated vector is zero vector\n",
        "                agg = proj.new_zeros(self.out_ch)\n",
        "                e_logits = torch.tensor([])\n",
        "                alphas = torch.tensor([])\n",
        "            else:\n",
        "                neigh_proj = proj[sampled]  # (n_neighbors, out_ch)\n",
        "                node_proj = proj[node_id].unsqueeze(0).repeat(neigh_proj.size(0), 1)  # (n_neighbors, out_ch)\n",
        "                concat = torch.cat([node_proj, neigh_proj], dim=1)  # (n_neighbors, 2*out_ch)\n",
        "                e = F.leaky_relu(self.attn[h](concat).view(-1), negative_slope=self.leaky_slope)  # (n_neighbors,)\n",
        "                alpha = torch.softmax(e, dim=0)\n",
        "                agg = (alpha.unsqueeze(1) * neigh_proj).sum(dim=0)  # (out_ch,)\n",
        "                e_logits = e.detach().cpu()\n",
        "                alphas = alpha.detach().cpu()\n",
        "            head_outputs.append(agg)\n",
        "            head_info.append({'e_logits': e_logits, 'alphas': alphas, 'head_proj_node': projections[h][node_id].detach().cpu(), 'head_agg': agg.detach().cpu()})\n",
        "        # final output: concatenate heads (common in GAT before final projection)\n",
        "        final = torch.cat([h.unsqueeze(0) for h in head_outputs], dim=0).view(-1)  # combined vector (heads*out_ch,)\n",
        "        info['heads'] = head_info\n",
        "        info['final'] = final.detach().cpu()\n",
        "        if return_per_head:\n",
        "            return final, info, head_outputs\n",
        "        return final, info\n",
        "\n",
        "\n",
        "def show_gat_internals(ds_name:str='Cora', node_id:int=42, heads:int=4, sample_size:int=8, seed:int=0):\n",
        "    torch.manual_seed(seed)\n",
        "    dataset = datasets[ds_name]\n",
        "    data = dataset[0]\n",
        "    layer = GATVerboseLayer(data.num_node_features, 8, heads=heads)  # use small out_ch for demonstration\n",
        "    final, info = layer(data, node_id=node_id, sample_size=sample_size)\n",
        "    print(f\"Dataset: {ds_name}\")\n",
        "    print(f\"Target node: {node_id}\")\n",
        "    neighbors = info['neighbors']\n",
        "    sampled = info['sampled_neighbors']\n",
        "    print(f\"Neighbors ({len(neighbors)}): {neighbors}\")\n",
        "    print(f\"Sampled ({len(sampled)}): {sampled}\")\n",
        "    for i, h in enumerate(info['heads']):\n",
        "        logits_preview = [round(float(x),4) for x in h['e_logits'][:6]] if h['e_logits'].numel() else []\n",
        "        alpha_preview = [round(float(x),4) for x in h['alphas'][:6]] if h['alphas'].numel() else []\n",
        "        proj_preview = [round(float(x),4) for x in h['head_proj_node'][:6]]\n",
        "        agg_preview = [round(float(x),4) for x in h['head_agg'][:6]] if h['head_agg'].numel() else []\n",
        "        print(f\"Head {i}: proj (first 6 dims): {proj_preview}\")\n",
        "        print(f\"Head {i}: logits (first {min(6,len(logits_preview))}): {logits_preview}\")\n",
        "        print(f\"Head {i}: alphas (first {min(6,len(alpha_preview))}): {alpha_preview}\")\n",
        "        print(f\"Head {i}: aggregated (first 6 dims): {agg_preview}\")\n",
        "    final_preview = [round(float(x),4) for x in info['final'][:12]]\n",
        "    print(f\"Concatenated final (first 12 dims): {final_preview}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2554c9ff",
      "metadata": {
        "id": "2554c9ff"
      },
      "outputs": [],
      "source": [
        "# Example demo: show the internals of a GAT layer for a selected node\n",
        "show_gat_internals(ds_name='Cora', node_id=42, heads=4, sample_size=6, seed=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81c7485e",
      "metadata": {
        "id": "81c7485e"
      },
      "source": [
        "### 3.5 GIN: Equations & Intuition\n",
        "- **Neighbor aggregation:** $h_{\\mathcal{N}(v)}^{(k)} = \\sum\\limits_{u \\in \\mathcal{N}(v)} h_u^{(k)}$\n",
        "- **Epsilon-adjusted sum:** $s_v^{(k)} = (1 + \\epsilon^{(k)}) h_v^{(k)} + h_{\\mathcal{N}(v)}^{(k)}$\n",
        "- **MLP update:** $h_v^{(k+1)} = \\text{MLP}^{(k)}\\!\\left(s_v^{(k)}\\right)$\n",
        "- **Optional readout:** $h_{\\mathcal{G}} = \\text{READOUT}\\left(\\{h_v^{(K)} \\mid v \\in \\mathcal{V}\\}\\right)$\n",
        "\n",
        "**TODO (students):**\n",
        "- Try enabling `learn_eps=True` in the `GINVerboseLayer` and observe how `eps` is learned during training or inspection.\n",
        "- Compare the outputs for `eps=0` and `eps=0.1` for the same node."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2a912a0",
      "metadata": {
        "id": "d2a912a0"
      },
      "source": [
        "### GIN Internals Walkthrough\n",
        "This walkthrough implements a verbose GIN layer that explicitly performs neighbor summation, epsilon-adjusted self-weighting, and MLP update, showing intermediate tensors so students can track how the GIN update works for a selected node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b7a334",
      "metadata": {
        "id": "b3b7a334"
      },
      "outputs": [],
      "source": [
        "class GINVerboseLayer(nn.Module):\n",
        "    \"\"\"Pedagogical GIN layer: sum neighbors, add (1+eps)*x_v, pass through an MLP, and show internals.\"\"\"\n",
        "    def __init__(self, in_ch:int, hid:int, eps:float=0.0, learn_eps:bool=False):\n",
        "        super().__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.hid = hid\n",
        "        if learn_eps:\n",
        "            self.eps = nn.Parameter(torch.tensor(float(eps)))\n",
        "        else:\n",
        "            self.eps = float(eps)\n",
        "        # MLP matching the GIN architecture: two linear layers with ReLU\n",
        "        self.mlp = nn.Sequential(nn.Linear(in_ch, hid), nn.ReLU(), nn.Linear(hid, hid))\n",
        "    def forward(self, data, node_id:int, sample_size:int=None):\n",
        "        edge_index = data.edge_index\n",
        "        src, dst = edge_index\n",
        "        all_neighbors = torch.unique(src[dst == node_id])\n",
        "        info = {'neighbors': all_neighbors.tolist() if all_neighbors.numel() else []}\n",
        "        # sample neighbors for demonstration if requested\n",
        "        if all_neighbors.numel() == 0:\n",
        "            sampled = all_neighbors\n",
        "        elif sample_size is None or all_neighbors.numel() <= sample_size:\n",
        "            sampled = all_neighbors\n",
        "        else:\n",
        "            perm = torch.randperm(all_neighbors.numel())[:sample_size]\n",
        "            sampled = all_neighbors[perm]\n",
        "        info['sampled_neighbors'] = sampled.tolist() if sampled.numel() else []\n",
        "        if sampled.numel() == 0:\n",
        "            neighbor_sum = data.x.new_zeros((data.x.size(1),))\n",
        "        else:\n",
        "            neighbor_sum = data.x[sampled].sum(dim=0)  # sum over neighbor feature vectors\n",
        "        self_feat = data.x[node_id]\n",
        "        if isinstance(self.eps, float):\n",
        "            eps_val = self.eps\n",
        "        else:\n",
        "            eps_val = float(self.eps.detach().cpu()) if not self.eps.requires_grad else float(self.eps.detach().cpu())\n",
        "        s_v = (1.0 + eps_val) * self_feat + neighbor_sum\n",
        "        out = self.mlp(s_v)\n",
        "        info.update({\n",
        "            'neighbor_sum': neighbor_sum.detach().cpu(),\n",
        "            'eps': float(eps_val),\n",
        "            's_v': s_v.detach().cpu(),\n",
        "            'out': out.detach().cpu()\n",
        "        })\n",
        "        return out, info\n",
        "\n",
        "\n",
        "def show_gin_internals(ds_name:str='Cora', node_id:int=42, sample_size:int=8, eps:float=0.0, learn_eps:bool=False, seed:int=0):\n",
        "    torch.manual_seed(seed)\n",
        "    dataset = datasets[ds_name]\n",
        "    data = dataset[0]\n",
        "    layer = GINVerboseLayer(data.num_node_features, 32, eps=eps, learn_eps=learn_eps)\n",
        "    out, info = layer(data, node_id=node_id, sample_size=sample_size)\n",
        "    print(f\"Dataset: {ds_name}\")\n",
        "    print(f\"Target node: {node_id}\")\n",
        "    print(f\"Neighbors ({len(info['neighbors'])}): {info['neighbors']}\")\n",
        "    print(f\"Sampled ({len(info['sampled_neighbors'])}): {info['sampled_neighbors']}\")\n",
        "    neighbor_preview = [round(float(x),4) for x in info['neighbor_sum'][:5]]\n",
        "    s_v_preview = [round(float(x),4) for x in info['s_v'][:5]]\n",
        "    out_preview = [round(float(x),4) for x in info['out'][:5]]\n",
        "    print(f\"Neighbor sum (first 5 dims): {neighbor_preview}\")\n",
        "    print(f\"(1+eps) * self + sum (first 5 dims): {s_v_preview}\")\n",
        "    print(f\"MLP output (first 5 dims): {out_preview}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c16ec1e",
      "metadata": {
        "id": "9c16ec1e"
      },
      "outputs": [],
      "source": [
        "# Demo for GIN internals — adjust node id, eps, or sample size to experiment\n",
        "show_gin_internals(ds_name='Cora', node_id=42, sample_size=6, eps=0.0, learn_eps=False, seed=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23bf4eac",
      "metadata": {
        "id": "23bf4eac"
      },
      "source": [
        "### 7. PyTorch GNN Implementations\n",
        "(Reference implementations used in this notebook)\n",
        "\n",
        "**TODO:**\n",
        "- Compare the custom `Verbose` layers (GraphSAGEVerbose, GATVerbose, GINVerbose) to the built-in `GCNConv`, `SAGEConv`, `GATConv`, and `GINConv` implementations in PyG.\n",
        "- Try rewriting one model using low-level PyG primitives for educational purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a40d9a7d",
      "metadata": {
        "id": "a40d9a7d"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_ch, hid, out_ch):\n",
        "        super().__init__()\n",
        "        self.s1 = SAGEConv(in_ch, hid)\n",
        "        self.s2 = SAGEConv(hid, out_ch)\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.s1(x, edge_index))\n",
        "        return self.s2(x, edge_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "365d4cf3",
      "metadata": {
        "id": "365d4cf3"
      },
      "outputs": [],
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_ch, hid, out_ch):\n",
        "        super().__init__()\n",
        "        self.g1 = GATConv(in_ch, hid, heads=4)\n",
        "        self.g2 = GATConv(4*hid, out_ch)\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.elu(self.g1(x, edge_index))\n",
        "        return self.g2(x, edge_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23e7e0c9",
      "metadata": {
        "id": "23e7e0c9"
      },
      "outputs": [],
      "source": [
        "class GIN(torch.nn.Module):\n",
        "    def __init__(self, in_ch, hid, out_ch):\n",
        "        super().__init__()\n",
        "        self.g1 = GINConv(nn.Sequential(nn.Linear(in_ch, hid), nn.ReLU(), nn.Linear(hid, hid)))\n",
        "        self.g2 = GINConv(nn.Sequential(nn.Linear(hid, hid), nn.ReLU(), nn.Linear(hid, hid)))\n",
        "        self.head = nn.Linear(hid, out_ch)\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.g1(x, edge_index))\n",
        "        x = F.relu(self.g2(x, edge_index))\n",
        "        return self.head(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnoIyUU-tSBi"
      },
      "source": [
        "## 4. Training Helper Function\n",
        "\n",
        "This cell defines a `train()` helper that trains a model on a given `Data` object and returns the last output logits.\n",
        "\n",
        "**TODO:**\n",
        "- Modify the `train()` helper to accept different optimizers (SGD, AdamW) and compare training behavior.\n",
        "- Add an LR scheduler and observe whether training becomes more stable for deeper models."
      ],
      "id": "XnoIyUU-tSBi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecP-iSL9tSBi"
      },
      "outputs": [],
      "source": [
        "def train(model, data, epochs=60, device=None):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    data = data.to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        opt.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    model = model.to(\"cpu\")\n",
        "    data = data.to(\"cpu\")\n",
        "    return out.to(\"cpu\")\n"
      ],
      "id": "ecP-iSL9tSBi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FT8GBzWtSBi"
      },
      "source": [
        "## 5. Train and Compare Models\n",
        "\n",
        "This section trains all model classes and reports test accuracy for each dataset.\n",
        "\n",
        "**TODO:**\n",
        "- Try changing hidden sizes and the training epochs to see how accuracy varies."
      ],
      "id": "5FT8GBzWtSBi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f97b049",
      "metadata": {
        "id": "3f97b049"
      },
      "outputs": [],
      "source": [
        "# Accuracy vs Depth experiments\n",
        "import tqdm\n",
        "\n",
        "def build_gcn_depth(in_ch, hid, out_ch, depth):\n",
        "    class GCNDepth(torch.nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.layers = torch.nn.ModuleList()\n",
        "            if depth == 1:\n",
        "                self.layers.append(GCNConv(in_ch, out_ch))\n",
        "            else:\n",
        "                self.layers.append(GCNConv(in_ch, hid))\n",
        "                for _ in range(depth - 2):\n",
        "                    self.layers.append(GCNConv(hid, hid))\n",
        "                self.layers.append(GCNConv(hid, out_ch))\n",
        "        def forward(self, x, edge_index):\n",
        "            for i, layer in enumerate(self.layers):\n",
        "                x = layer(x, edge_index) if i == (len(self.layers)-1) else F.relu(layer(x, edge_index))\n",
        "            return x\n",
        "    return GCNDepth\n",
        "\n",
        "def build_sage_depth(in_ch, hid, out_ch, depth):\n",
        "    class SAGEDepth(torch.nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.layers = torch.nn.ModuleList()\n",
        "            if depth == 1:\n",
        "                self.layers.append(SAGEConv(in_ch, out_ch))\n",
        "            else:\n",
        "                self.layers.append(SAGEConv(in_ch, hid))\n",
        "                for _ in range(depth - 2):\n",
        "                    self.layers.append(SAGEConv(hid, hid))\n",
        "                self.layers.append(SAGEConv(hid, out_ch))\n",
        "        def forward(self, x, edge_index):\n",
        "            for i, layer in enumerate(self.layers):\n",
        "                x = layer(x, edge_index)\n",
        "                if i != (len(self.layers)-1):\n",
        "                    x = F.relu(x)\n",
        "            return x\n",
        "    return SAGEDepth\n",
        "\n",
        "# Simplify GAT stacking: use single head per layer to make dimensions straightforward\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "def build_gat_depth(in_ch, hid, out_ch, depth, heads=1):\n",
        "    class GATDepth(torch.nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.layers = torch.nn.ModuleList()\n",
        "            if depth == 1:\n",
        "                self.layers.append(GATConv(in_ch, out_ch, heads=heads))\n",
        "            else:\n",
        "                self.layers.append(GATConv(in_ch, hid, heads=heads))\n",
        "                for _ in range(depth - 2):\n",
        "                    self.layers.append(GATConv(hid * heads, hid, heads=heads))\n",
        "                self.layers.append(GATConv(hid * heads, out_ch, heads=1))\n",
        "        def forward(self, x, edge_index):\n",
        "            for i, layer in enumerate(self.layers):\n",
        "                x = layer(x, edge_index)\n",
        "                if i != (len(self.layers)-1):\n",
        "                    x = F.elu(x)\n",
        "            return x\n",
        "    return GATDepth\n",
        "\n",
        "# GIN depth builder\n",
        "from torch_geometric.nn import GINConv\n",
        "\n",
        "def build_gin_depth(in_ch, hid, out_ch, depth):\n",
        "    class GINDepth(torch.nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.layers = torch.nn.ModuleList()\n",
        "            if depth == 1:\n",
        "                self.layers.append(GINConv(nn.Sequential(nn.Linear(in_ch, out_ch), nn.ReLU(), nn.Linear(out_ch, out_ch))))\n",
        "            else:\n",
        "                self.layers.append(GINConv(nn.Sequential(nn.Linear(in_ch, hid), nn.ReLU(), nn.Linear(hid, hid))))\n",
        "                for _ in range(depth - 2):\n",
        "                    self.layers.append(GINConv(nn.Sequential(nn.Linear(hid, hid), nn.ReLU(), nn.Linear(hid, hid))))\n",
        "                self.layers.append(GINConv(nn.Sequential(nn.Linear(hid, out_ch), nn.ReLU(), nn.Linear(out_ch, out_ch))))\n",
        "        def forward(self, x, edge_index):\n",
        "            for i, layer in enumerate(self.layers):\n",
        "                x = layer(x, edge_index)\n",
        "                if i != (len(self.layers)-1):\n",
        "                    x = F.relu(x)\n",
        "            return x\n",
        "    return GINDepth\n",
        "\n",
        "\n",
        "def accuracy_vs_depth(datasets, depth_range=range(1, 7), epochs=40, hidden_size=32, gat_hidden=8, device=None):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    results_depth = {ds_name: { 'GCN': [], 'GraphSAGE': [], 'GAT': [], 'GIN': []} for ds_name in datasets.keys()}\n",
        "    for ds_name, ds in datasets.items():\n",
        "        print(f\"Running depth sweep for dataset: {ds_name}\")\n",
        "        dataset = ds\n",
        "        data = dataset[0]\n",
        "        for depth in depth_range:\n",
        "            print(f\"  Depth: {depth}\")\n",
        "            # Build models for this depth\n",
        "            GCNModel = build_gcn_depth(data.num_node_features, hidden_size, dataset.num_classes, depth)\n",
        "            SAGEModel = build_sage_depth(data.num_node_features, hidden_size, dataset.num_classes, depth)\n",
        "            GATModel = build_gat_depth(data.num_node_features, gat_hidden, dataset.num_classes, depth, heads=1)\n",
        "            GINModel = build_gin_depth(data.num_node_features, hidden_size, dataset.num_classes, depth)\n",
        "\n",
        "            models = {\n",
        "                'GCN': GCNModel(),\n",
        "                'GraphSAGE': SAGEModel(),\n",
        "                'GAT': GATModel(),\n",
        "                'GIN': GINModel()\n",
        "            }\n",
        "\n",
        "            for name, model in models.items():\n",
        "                out = train(model, data, epochs=epochs, device=device)\n",
        "                pred = out.argmax(dim=1)\n",
        "                acc = (pred[data.test_mask] == data.y[data.test_mask]).float().mean()\n",
        "                results_depth[ds_name][name].append(float(acc))\n",
        "    return results_depth\n",
        "\n",
        "# Run a quick sweep (smaller epochs so the interactive demo completes faster)\n",
        "depth_range = range(1, 7)  # 1..6 layers\n",
        "results_depth = accuracy_vs_depth(datasets, depth_range=depth_range, epochs=30, hidden_size=32, gat_hidden=8)\n",
        "\n",
        "# Plotting Results: one panel per dataset showing accuracy vs depth for each model\n",
        "import numpy as np\n",
        "\n",
        "for ds_name, res in results_depth.items():\n",
        "    plt.figure(figsize=(7,4))\n",
        "    for model_name, accs in res.items():\n",
        "        plt.plot(list(depth_range), accs, marker='o', label=model_name)\n",
        "    plt.xlabel('Number of Layers (Depth)')\n",
        "    plt.ylabel('Test Accuracy')\n",
        "    plt.title(f'Accuracy vs Depth: {ds_name}')\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    plt.xticks(list(depth_range))\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa7ff867",
      "metadata": {
        "id": "aa7ff867"
      },
      "outputs": [],
      "source": [
        "# Visualize test accuracy results across datasets and models\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # optional; falls back to matplotlib if not present\n",
        "sns.set_style('whitegrid')\n",
        "%matplotlib inline\n",
        "\n",
        "# Convert results to DataFrame: rows are datasets, cols are model names\n",
        "df = pd.DataFrame.from_dict(results, orient='index')\n",
        "# Reorder columns if needed - keep consistent model display order\n",
        "model_order = ['GIN', 'GraphSAGE', 'GAT']\n",
        "cols_to_plot = [c for c in model_order if c in df.columns]  # defensive ordering\n",
        "df = df[cols_to_plot]\n",
        "\n",
        "# Grouped bar chart: model accuracies per dataset\n",
        "fig, ax = plt.subplots(figsize=(9, 5))\n",
        "df.plot(kind='bar', ax=ax, rot=0, width=0.8)\n",
        "ax.set_ylim(0.0, 1.0)\n",
        "ax.set_ylabel('Test Accuracy')\n",
        "ax.set_title('Test Accuracy by Model and Dataset')\n",
        "ax.legend(title='Model')\n",
        "# Annotate the bars with percentage\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    if height is not None and not (height != height):  # avoid NaN\n",
        "        ax.annotate(f\"{height:.2%}\", (p.get_x() + p.get_width() / 2, height),\n",
        "                    ha='center', va='bottom', fontsize=9, rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Heatmap view for quick comparison (datasets x models)\n",
        "plt.figure(figsize=(6, 3))\n",
        "sns.heatmap(df, annot=True, fmt='.3f', cmap='viridis', cbar=True)\n",
        "plt.title('Accuracy Heatmap (dataset rows, models columns)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Dataset')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr24DQr5tSBj"
      },
      "source": [
        "## 6. Over-Smoothing Demo\n",
        "\n",
        "The demo below shows the standard deviation of node embeddings as the GCN layer is applied repeatedly.\n",
        "\n",
        "**TODO (students):**\n",
        "- Execute the over-smoothing demo for GCN, GraphSAGE, GAT and GIN (we added code for all of these) and plot the embedding standard deviation curves (already included in the notebook).\n",
        "- Try dropout, residuals, and attention variants and observe how the std curves change.\n",
        "- Compute mean pairwise cosine similarity across a subset of nodes as another measure of smoothing."
      ],
      "id": "xr24DQr5tSBj"
    },
    {
      "cell_type": "markdown",
      "id": "14b1c748",
      "metadata": {
        "id": "14b1c748"
      },
      "source": [
        "### Over-Smoothing: Intuition, Measurement & Mitigation\n",
        "\n",
        "- **What is over-smoothing?**\n",
        "  - Over-smoothing is the phenomenon where, as message-passing / graph convolutional layers are stacked, node embeddings become indistinguishable — i.e., they converge to a subspace where nodes in the graph (or even across communities) map to similar feature vectors. This typically causes a degradation in downstream performance on tasks that depend on node-level differentiation like node classification.\n",
        "\n",
        "- **Why it happens (intuition):**\n",
        "  - Many graph convolutional operators (e.g., GCN) act like low-pass filters on the graph: they mix a node's own features with its neighbors' features repeatedly. Repeating such filtering operations is like applying a smoothing operator many times, which reduces high-frequency (i.e., discriminative) components and increases low-frequency components shared by many nodes. Formally, repeated application of a normalized adjacency (or Laplacian-like) operator drives representations toward eigenvectors associated with the largest eigenvalues — information is lost for representations that need higher-frequency components.\n",
        "\n",
        "- **Observables / How to measure it in practice:**\n",
        "  - **Embedding Std per layer:** a simple test is to repeatedly apply the GNN layer (without training) and report the standard deviation across node embeddings at each layer — low std indicates collapsed/indistinguishable embeddings.\n",
        "  - **Average pairwise cosine similarity:** compute mean pairwise cosine similarity (or a random subset for efficiency); an increase towards 1.0 indicates nodes are becoming more similar.\n",
        "  - **Classification accuracy vs depth:** plot training or test accuracy as a function of the number of layers. If performance drops with increasing depth, over-smoothing may be one cause.\n",
        "  - **Visualizations (PCA/t-SNE):** project embeddings from different layers to 2D to see whether clusters collapse as layers increase.\n",
        "  - **Feature variance per feature-dimension:** monitor the per-dimension variance as layers grow.\n",
        "\n",
        "- **Mitigation strategies (practical techniques):**\n",
        "  - **Residual / skip connections** between layers (ResGCN, Skip connections / JKNet) to retain earlier information and break repeated mixing.\n",
        "  - **Normalization** (BatchNorm / LayerNorm) per layer to stabilize learning and maintain variance.\n",
        "  - **DropEdge** or stochastic edge removal to reduce excessive mixing per step.\n",
        "  - **Attention mechanisms** (GAT) or per-edge weighting to focus information flow on key neighbors rather than uniformly pooling everything.\n",
        "  - **Control the receptive field** using sampling (GraphSAGE) or limiting neighborhood depth and using local aggregators.\n",
        "  - **Jump-Knowledge connections** to aggregate information from multiple layer depths rather than just final layer embeddings.\n",
        "  - **Stronger, expressive aggregators** like GIN which may discriminate node neighborhoods better and be less prone to losing discriminative features when used carefully.\n",
        "  - **Regularization & Task supervision** on intermediate layer outputs (auxiliary losses at intermediate layers) forcing earlier layers to preserve discriminative signal.\n",
        "  - **Shallow networks** — sometimes reducing the number of layers is the simplest and most effective fix for over-smoothing in a given dataset.\n",
        "\n",
        "- **Suggested experiments you can try in the notebook:**\n",
        "  1. Repeat the current Std experiment for GCN, GraphSAGE, GAT and GIN and plot the Std curves to compare sensitivity to over-smoothing.\n",
        "  2. Compute mean pairwise cosine similarity at each depth (or sample-subset for large graphs) and plot it to visualize how quickly similarity grows.\n",
        "  3. For one dataset, compute test accuracy vs number of layers for each model and plot the curves.\n",
        "  4. Add residual connections and repeat the Std/cosine similarity experiments to show how residuals slow down the smoothing.\n",
        "  5. Visualize t-SNE/PCA of embeddings at depths {0, 1, 3, 6} and compare how clusters collapse or stay separated across different models.\n",
        "\n",
        "> Tip: many of these experiments can be run quickly with a smaller `sampled` subset of nodes for similarity plotting to avoid O(N^2) cost.\n",
        "\n",
        "- **Interpretation of the demo output:**\n",
        "  - A falling STD (and rising mean pairwise similarity) means the model is mixing neighborhood information heavily and losing discriminative features between nodes. If accuracy drops as depth increases, it’s likely due to over-smoothing rather than insufficient capacity — try the mitigation strategies above to see their effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4783b098",
      "metadata": {
        "id": "4783b098"
      },
      "outputs": [],
      "source": [
        "# Plotting Embedding Standard Deviation vs Layer for Each Model and Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_theme(style='whitegrid')\n",
        "torch.manual_seed(0)  # reproducible demo\n",
        "max_layers = 12\n",
        "model_factories = {\n",
        "    'GCN': lambda nf: GCNConv(nf, nf),\n",
        "    'GraphSAGE': lambda nf: SAGEConv(nf, nf),\n",
        "    'GAT': lambda nf: GATConv(nf, nf, heads=1),\n",
        "}\n",
        "results_std = {}\n",
        "for ds_name, ds in datasets.items():\n",
        "    dataset = ds\n",
        "    data = dataset[0]\n",
        "    nf = dataset.num_node_features\n",
        "    results_std[ds_name] = {}\n",
        "    for model_name, factory in model_factories.items():\n",
        "        conv = factory(nf)\n",
        "        x_curr = data.x.clone()\n",
        "        stds = []\n",
        "        with torch.no_grad():\n",
        "            for layer in range(max_layers):\n",
        "                stds.append(x_curr.std().item())\n",
        "                x_curr = conv(x_curr, data.edge_index)\n",
        "        results_std[ds_name][model_name] = stds\n",
        "# Build DataFrame and plot per dataset\n",
        "for ds_name, models in results_std.items():\n",
        "    df = pd.DataFrame(models, index=list(range(max_layers)))\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    for col in df.columns:\n",
        "        plt.plot(df.index, df[col], marker='o', label=col)\n",
        "    plt.xlabel('Layer')\n",
        "    plt.ylabel('Embedding Std')\n",
        "    plt.title(f'Embedding Std vs Layer — {ds_name}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "# Combined heatmap at max depth to compare models per dataset\n",
        "final_stds = {ds_name: {m: vals[-1] for m, vals in models.items()} for ds_name, models in results_std.items()}\n",
        "df_final = pd.DataFrame(final_stds).T  # datasets x models\n",
        "plt.figure(figsize=(6, 3))\n",
        "sns.heatmap(df_final, annot=True, fmt='.4f', cmap='mako')\n",
        "plt.title('Embedding Std at final layer (lower => more smoothing)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Dataset')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}