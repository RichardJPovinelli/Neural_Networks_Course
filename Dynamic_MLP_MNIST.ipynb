{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b29ecc6",
   "metadata": {},
   "source": [
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RichardJPovinelli/Neural_Networks_Course/blob/main/Dynamic_MLP_MNIST.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "839cd6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import time\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "\n",
    "    WIDGETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WIDGETS_AVAILABLE = False\n",
    "\n",
    "# Global run control flag (used by Abort button)\n",
    "STOP_REQUESTED = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6e56b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "71272b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 55000, Val: 5000, Test: 10000\n"
     ]
    }
   ],
   "source": [
    "# Data Loaders (MNIST)\n",
    "batch_size_default = 128\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_ds = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "# Split train into train/val\n",
    "val_size = 5000\n",
    "train_size = len(train_ds) - val_size\n",
    "train_ds, val_ds = torch.utils.data.random_split(\n",
    "    train_ds, [train_size, val_size], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "\n",
    "def make_loaders(batch_size):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=batch_size, shuffle=True),\n",
    "        DataLoader(val_ds, batch_size=batch_size, shuffle=False),\n",
    "        DataLoader(test_ds, batch_size=batch_size, shuffle=False),\n",
    "    )\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader = make_loaders(batch_size_default)\n",
    "print(f\"Train: {train_size}, Val: {val_size}, Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ac7bd699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param count test model: 134794\n"
     ]
    }
   ],
   "source": [
    "# Dynamic MLP Model with optional BatchNorm, Dropout, Residual Blocks\n",
    "class DynamicMLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=28 * 28,\n",
    "        num_classes=10,\n",
    "        hidden_width=256,\n",
    "        depth=4,\n",
    "        activation=\"relu\",\n",
    "        dropout=0.0,\n",
    "        batchnorm=False,\n",
    "        residual=False,\n",
    "        widths_list=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        act_map = {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"gelu\": nn.GELU(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "            \"leakyrelu\": nn.LeakyReLU(0.2),\n",
    "            \"elu\": nn.ELU(),\n",
    "        }\n",
    "        self.activation = act_map[activation.lower()]\n",
    "        self.dropout_p = dropout\n",
    "        self.batchnorm = batchnorm\n",
    "        self.residual = residual\n",
    "        if widths_list is not None and len(widths_list) > 0:\n",
    "            widths = widths_list\n",
    "            depth = len(widths)\n",
    "        else:\n",
    "            widths = [hidden_width] * depth\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        self.skip_dims = []\n",
    "        for w in widths:\n",
    "            block = []\n",
    "            linear = nn.Linear(prev, w)\n",
    "            block.append(linear)\n",
    "            if batchnorm:\n",
    "                block.append(nn.BatchNorm1d(w))\n",
    "            block.append(self.activation)\n",
    "            if self.dropout_p > 0:\n",
    "                block.append(nn.Dropout(self.dropout_p))\n",
    "            layers.append(nn.Sequential(*block))\n",
    "            self.skip_dims.append((prev, w))\n",
    "            prev = w\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.out = nn.Linear(prev, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = x\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            inp = out\n",
    "            out = layer(out)\n",
    "            if self.residual:\n",
    "                in_dim, out_dim = self.skip_dims[i]\n",
    "                if in_dim == out_dim:\n",
    "                    out = out + inp\n",
    "        return self.out(out)\n",
    "\n",
    "    def count_params(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "# Quick sanity test\n",
    "model_test = DynamicMLP(depth=3, hidden_width=128, activation=\"relu\", residual=True)\n",
    "print(\"Param count test model:\", model_test.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "38aea678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history: dict, title: str = \"Training History\"):\n",
    "    epochs = history.get(\"epoch\") or []\n",
    "    if not epochs:\n",
    "        print(\"No history data available to plot.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    axes[0].plot(epochs, history.get(\"train_loss\", []), label=\"Train Loss\")\n",
    "    axes[0].plot(epochs, history.get(\"val_loss\", []), label=\"Val Loss\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].set_title(\"Loss\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(epochs, history.get(\"train_error\", []), label=\"Train Error\")\n",
    "    axes[1].plot(epochs, history.get(\"val_error\", []), label=\"Val Error\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Error Rate\")\n",
    "    axes[1].set_title(\"Error\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_run_log(metric: str = \"test_error\"):\n",
    "    \"\"\"Plot a bar chart of the requested metric across runs and show a short description for each run beneath the chart.\n",
    "\n",
    "    The function uses the top axis for the metric chart and the bottom axis to list the run descriptions, wrapped and left-justified.\n",
    "    \"\"\"\n",
    "    if not EXPERIMENT_LOG:\n",
    "        print(\"No experiment log entries to plot yet.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(EXPERIMENT_LOG)\n",
    "    if metric not in df.columns:\n",
    "        print(f\"Metric '{metric}' not found in experiment log columns: {sorted(df.columns.tolist())}\")\n",
    "        return\n",
    "\n",
    "    # Prepare data\n",
    "    runs = df.index + 1\n",
    "    values = df[metric]\n",
    "\n",
    "    # Short labels for xticks: simply run numbers to avoid overlap\n",
    "    xtick_labels = [str(int(r)) for r in runs]\n",
    "\n",
    "    # Full descriptions for display under the plot\n",
    "    def _full_desc(row, idx):\n",
    "        widths = row.get(\"widths_list\")\n",
    "        width_desc = f\"widths={widths}\" if widths and isinstance(widths, (list, tuple)) else f\"hidden={int(row.get('hidden_width', 0))}\"\n",
    "        return (\n",
    "            f\"Run {idx}: depth={row.get('depth')}, {width_desc}, act={row.get('activation')}, opt={row.get('optimizer')}, \"\n",
    "            f\"epochs={row.get('epochs')}, batch={row.get('batch_size')}, {metric}={row.get(metric)}\"\n",
    "        )\n",
    "\n",
    "    descriptions = [_full_desc(row, int(idx) + 1) for idx, row in df.iterrows()]\n",
    "\n",
    "    # Wrap long description lines for readability\n",
    "    import textwrap\n",
    "    wrap_width = 100\n",
    "    wrapped_lines = []\n",
    "    for d in descriptions:\n",
    "        wrapped_lines.extend(textwrap.wrap(d, wrap_width) or [d])\n",
    "\n",
    "    # Limit number of lines shown to keep figure readable\n",
    "    max_lines = 12\n",
    "    if len(wrapped_lines) > max_lines:\n",
    "        wrapped_lines = wrapped_lines[:max_lines]\n",
    "        wrapped_lines.append(f\"... and {len(descriptions) - max_lines} more runs (see EXPERIMENT_LOG)\")\n",
    "\n",
    "    # Dynamic height based on number of description lines\n",
    "    top_height = 3\n",
    "    bottom_height = 0.25 * max(len(wrapped_lines), 1)\n",
    "    fig_height = top_height + bottom_height\n",
    "\n",
    "    # Create figure and axes with sufficient spacing for xticks and descriptions\n",
    "    import matplotlib.gridspec as gridspec\n",
    "    fig = plt.figure(figsize=(max(8, len(runs) * 0.8), fig_height))\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[top_height, bottom_height], hspace=0.4)\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "    ax_desc = fig.add_subplot(gs[1])\n",
    "\n",
    "    # Plot bar chart\n",
    "    bars = ax.bar(runs, values, color=\"#1f77b4\")\n",
    "    ax.set_xticks(runs)\n",
    "    ax.set_xticklabels(xtick_labels, rotation=0, ha='center', fontsize=9)\n",
    "    ax.set_xlabel(\"Run #\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(f\"Experiment Log — {metric}\")\n",
    "    ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "\n",
    "    # Render descriptions in the bottom axes\n",
    "    ax_desc.axis('off')\n",
    "    text_block = \"\\n\".join(wrapped_lines)\n",
    "    ax_desc.text(0.01, 0.98, text_block, va='top', ha='left', family='monospace', fontsize=9, transform=ax_desc.transAxes)\n",
    "\n",
    "    # Avoid using tight_layout if there are non-standard Axes in the figure; instead adjust subplots\n",
    "    fig.subplots_adjust(left=0.06, right=0.98, top=0.95, bottom=0.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b917a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_predictions(model, loader, device=torch.device('cpu'), n_correct=4, n_incorrect=4):\n",
    "    \"\"\"Plot n_correct correct predictions and n_incorrect incorrect predictions found by the model on data from `loader`.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    # Guard short-circuit if either the model or loader is not available\n",
    "    if model is None:\n",
    "        print(\"No model provided; skipping example predictions.\")\n",
    "        return\n",
    "    if loader is None:\n",
    "        print(\"No test_loader available; skipping example predictions.\")\n",
    "        return\n",
    "\n",
    "    model.eval()\n",
    "    correct_ex = []\n",
    "    incorrect_ex = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            for i in range(xb.size(0)):\n",
    "                img = xb[i].cpu().squeeze(0) if xb.shape[1] == 1 else xb[i].cpu()\n",
    "                true = int(yb[i].cpu())\n",
    "                pred = int(preds[i].cpu())\n",
    "                if pred == true and len(correct_ex) < n_correct:\n",
    "                    correct_ex.append((img.numpy(), true, pred))\n",
    "                elif pred != true and len(incorrect_ex) < n_incorrect:\n",
    "                    incorrect_ex.append((img.numpy(), true, pred))\n",
    "                if len(correct_ex) >= n_correct and len(incorrect_ex) >= n_incorrect:\n",
    "                    break\n",
    "            if len(correct_ex) >= n_correct and len(incorrect_ex) >= n_incorrect:\n",
    "                break\n",
    "    # Prepare plot\n",
    "    import matplotlib.pyplot as plt\n",
    "    ncols = max(n_correct, n_incorrect)\n",
    "    fig, axes = plt.subplots(2, ncols, figsize=(ncols * 1.6, 4))\n",
    "    # Top row: correct\n",
    "    for c in range(ncols):\n",
    "        ax = axes[0, c] if ncols > 1 else axes[0]\n",
    "        if c < len(correct_ex):\n",
    "            img, t, p = correct_ex[c]\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.set_title(f't:{t} p:{p}')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    # Bottom row: incorrect\n",
    "    for c in range(ncols):\n",
    "        ax = axes[1, c] if ncols > 1 else axes[1]\n",
    "        if c < len(incorrect_ex):\n",
    "            img, t, p = incorrect_ex[c]\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.set_title(f't:{t} p:{p}')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.suptitle('Sample Predictions — Top: correct | Bottom: incorrect')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc1a82",
   "metadata": {},
   "source": [
    "### Set up GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "9ed6e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Widgets (if available)\n",
    "from ipywidgets import Layout, GridBox\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "# Defensive cleanup: close existing widget objects to avoid stale front-end/back-end state.\n",
    "for _n in [\n",
    "    \"depth_w\",\n",
    "    \"width_w\",\n",
    "    \"widths_text\",\n",
    "    \"act_w\",\n",
    "    \"optimizer_w\",\n",
    "    \"lr_w\",\n",
    "    \"dropout_w\",\n",
    "    \"batchnorm_w\",\n",
    "    \"residual_w\",\n",
    "    \"scheduler_w\",\n",
    "    \"step_size_w\",\n",
    "    \"epochs_w\",\n",
    "    \"batch_w\",\n",
    "    \"metric_dropdown\",\n",
    "    \"run_button\",\n",
    "    \"abort_button\",\n",
    "    \"log_area\",\n",
    "    \"figure_out\",\n",
    "    \"grid\",\n",
    "    \"button_row\",\n",
    "    \"container\",\n",
    "]:\n",
    "    try:\n",
    "        if _n in globals() and hasattr(globals()[_n], \"close\"):\n",
    "            globals()[_n].close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "def on_abort(b):\n",
    "    global STOP_REQUESTED\n",
    "    STOP_REQUESTED = True\n",
    "    abort_button.disabled = True\n",
    "    # Append message to the log textarea\n",
    "    log_area.value = log_area.value + \"Abort requested — the current run will stop shortly.\\n\"\n",
    "\n",
    "\n",
    "def on_run(b):\n",
    "    run_button.disabled = True\n",
    "    abort_button.disabled = False\n",
    "    # Clear previous log and append new header\n",
    "    log_area.value = \"\"\n",
    "    figure_out.clear_output()\n",
    "    if widths_text.value.strip():\n",
    "        try:\n",
    "            wl = [int(x.strip()) for x in widths_text.value.split(\",\") if x.strip()]\n",
    "        except ValueError:\n",
    "            log_area.value += \"Invalid widths list; using uniform width.\\n\"\n",
    "            wl = None\n",
    "    else:\n",
    "        wl = None\n",
    "    try:\n",
    "        lr_val = float(lr_w.value)\n",
    "    except (TypeError, ValueError):\n",
    "        lr_val = 1e-3\n",
    "        log_area.value += \"Learning rate unparsable; resetting to 1e-3.\\n\"\n",
    "    if lr_val < lr_min:\n",
    "        lr_val = lr_min\n",
    "        log_area.value += f\"Learning rate too small; clamped to {lr_min:.1e}.\\n\"\n",
    "    elif lr_val > lr_max:\n",
    "        lr_val = lr_max\n",
    "        log_area.value += f\"Learning rate too large; clamped to {lr_max:.1e}.\\n\"\n",
    "    lr_w.value = lr_val\n",
    "    cfg = RunConfig(\n",
    "        depth=depth_w.value,\n",
    "        hidden_width=width_w.value,\n",
    "        activation=act_w.value,\n",
    "        dropout=dropout_w.value,\n",
    "        batchnorm=batchnorm_w.value,\n",
    "        residual=residual_w.value,\n",
    "        optimizer=optimizer_w.value,\n",
    "        lr=lr_val,\n",
    "        epochs=epochs_w.value,\n",
    "        batch_size=batch_w.value,\n",
    "        scheduler=scheduler_w.value,\n",
    "        step_size=step_size_w.value,\n",
    "        widths_list=wl,\n",
    "    )\n",
    "    if cfg.optimizer.lower() == \"lm\" and cfg.scheduler:\n",
    "        log_area.value += \"Scheduler request ignored: LM optimizer does not support StepLR.\\n\"\n",
    "    log_area.value += f\"Running with config: {cfg}\\n\"\n",
    "\n",
    "    class TextAreaWriter:\n",
    "        \"\"\"Stream stdout directly into the Textarea log.\"\"\"\n",
    "\n",
    "        def __init__(self, textarea):\n",
    "            self.textarea = textarea\n",
    "\n",
    "        def write(self, text):\n",
    "            if text:\n",
    "                try:\n",
    "                    self.textarea.value += text\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        def flush(self):\n",
    "            pass\n",
    "\n",
    "    writer = TextAreaWriter(log_area)\n",
    "    with redirect_stdout(writer):\n",
    "        model, history = run_experiment(cfg)\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    opt_label = history.get(\"optimizer_used\", cfg.optimizer)\n",
    "    with figure_out:\n",
    "        from IPython.display import clear_output\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plot_history(history, title=f\"Error Curves (opt={opt_label}, depth={cfg.depth})\")\n",
    "        plot_run_log(metric_dropdown.value)\n",
    "        # Show sample predictions: top row correct, bottom row incorrect (4 each).\n",
    "        try:\n",
    "            plot_example_predictions(model, test_loader, device=device, n_correct=4, n_incorrect=4)\n",
    "        except Exception as ex:\n",
    "            print(\"Error plotting example predictions:\", ex)\n",
    "\n",
    "    run_button.disabled = False\n",
    "    abort_button.disabled = True\n",
    "\n",
    "\n",
    "# Widget styles & layout\n",
    "# Use flexible control layout (responsive)\n",
    "# Use a larger min_width + flex to prevent overlap of inputs on small displays\n",
    "default_ctrl_layout = Layout(width=\"auto\", min_width=\"220px\", flex=\"1 1 280px\")\n",
    "hbox_layout = Layout(\n",
    "    align_items=\"flex-start\",\n",
    "    display=\"flex\",\n",
    "    flex_flow=\"row wrap\",\n",
    "    justify_content=\"flex-start\",\n",
    "    width=\"100%\",\n",
    ")\n",
    "vbox_layout = Layout(width=\"100%\")\n",
    "\n",
    "# Shared bounds for learning-rate validation\n",
    "lr_min, lr_max = 1e-7, 1e-1\n",
    "\n",
    "# Core widgets\n",
    "depth_w = widgets.BoundedIntText(\n",
    "    value=4,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description=\"Number of Layers\",\n",
    "    layout=default_ctrl_layout,\n",
    ")\n",
    "width_w = widgets.BoundedIntText(\n",
    "    value=256,\n",
    "    min=16,\n",
    "    max=1024,\n",
    "    step=16,\n",
    "    description=\"Neurons per layer\",\n",
    "    layout=default_ctrl_layout,\n",
    ")\n",
    "widths_text = widgets.Text(\n",
    "    value=\"\",\n",
    "    description=\"Widths List\",\n",
    "    placeholder=\"Comma-separated custom widths (optional)\",\n",
    "    layout=default_ctrl_layout,\n",
    ")\n",
    "act_w = widgets.Dropdown(\n",
    "    options=[\"relu\", \"gelu\", \"tanh\", \"sigmoid\", \"leakyrelu\", \"elu\"],\n",
    "    value=\"relu\",\n",
    "    description=\"Activation\",\n",
    "    layout=default_ctrl_layout,\n",
    ")\n",
    "optimizer_w = widgets.Dropdown(\n",
    "    options=[\"adam\", \"adamw\", \"sgd\", \"lm\"],\n",
    "    value=\"adam\",\n",
    "    description=\"Optimizer\",\n",
    "    layout=default_ctrl_layout,\n",
    ")\n",
    "lr_w = widgets.BoundedFloatText(\n",
    "    value=1e-3,\n",
    "    min=lr_min,\n",
    "    max=lr_max,\n",
    "    step=1e-4,\n",
    "    description=\"Learning Rate\",\n",
    "    layout=default_ctrl_layout,\n",
    ")\n",
    "dropout_w = widgets.BoundedFloatText(\n",
    "    value=0.1,\n",
    "    min=0.0,\n",
    "    max=0.7,\n",
    "    step=0.05,\n",
    "    description=\"Dropout\",\n",
    "    layout=default_ctrl_layout,\n",
    ")\n",
    "batchnorm_w = widgets.ToggleButton(value=True, description=\"BatchNorm\", layout=Layout(width=\"130px\"))\n",
    "residual_w = widgets.ToggleButton(value=True, description=\"Residual\", layout=Layout(width=\"130px\"))\n",
    "scheduler_w = widgets.ToggleButton(value=False, description=\"Scheduler\", layout=Layout(width=\"130px\"))\n",
    "step_size_w = widgets.BoundedIntText(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description=\"Scheduler Step Size\",\n",
    "    layout=default_ctrl_layout,\n",
    ")\n",
    "epochs_w = widgets.BoundedIntText(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description=\"Epochs\",\n",
    "    layout=default_ctrl_layout,\n",
    ")\n",
    "batch_w = widgets.BoundedIntText(\n",
    "    value=128,\n",
    "    min=16,\n",
    "    max=512,\n",
    "    step=16,\n",
    "    description=\"Batch Size\",\n",
    "    layout=default_ctrl_layout,\n",
    ")\n",
    "metric_dropdown = widgets.Dropdown(\n",
    "    options=[\"test_error\", \"best_val_error\", \"test_loss\"],\n",
    "    value=\"test_error\",\n",
    "    description=\"Metric\",\n",
    "    layout=default_ctrl_layout,\n",
    ")\n",
    "\n",
    "run_button = widgets.Button(description=\"Run Experiment\", button_style=\"success\")\n",
    "abort_button = widgets.Button(description=\"Abort\", button_style=\"warning\", disabled=True)\n",
    "log_area = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder=\"Training output appears here...\",\n",
    "    layout=Layout(width=\"100%\", height=\"260px\"),\n",
    ")\n",
    "figure_out = widgets.Output(layout=Layout(border=\"1px solid #ccc\", width=\"100%\"))\n",
    "\n",
    "# Layout composition\n",
    "grid = GridBox(\n",
    "    children=(\n",
    "        depth_w,\n",
    "        width_w,\n",
    "        widths_text,\n",
    "        epochs_w,\n",
    "        batch_w,\n",
    "        dropout_w,\n",
    "        step_size_w,\n",
    "        lr_w,\n",
    "        optimizer_w,\n",
    "        act_w,\n",
    "        metric_dropdown,\n",
    "    ),\n",
    "    layout=Layout(\n",
    "        align_items=\"flex-start\",\n",
    "        grid_gap=\"8px\",\n",
    "        grid_template_columns=\"repeat(auto-fit, minmax(260px, 1fr))\",\n",
    "        width=\"100%\",\n",
    "    ),\n",
    ")\n",
    "button_row = widgets.HBox(\n",
    "    children=[run_button, abort_button, residual_w, batchnorm_w, scheduler_w],\n",
    "    layout=hbox_layout,\n",
    ")\n",
    "container = widgets.VBox(children=[grid, button_row, log_area, figure_out], layout=vbox_layout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a042d9b4",
   "metadata": {},
   "source": [
    "### Run Configuration Parameters\n",
    "- `Number of Layers (depth)`: number of hidden layers (ignored when `widths_list` is set; default 4).\n",
    "- `Neurons per layer (hidden_width)`: neurons per hidden layer when using uniform widths (default 256).\n",
    "- `Specify architecture (widths_list)`: optional explicit sequence of layer widths that overrides `hidden_width`/`depth`.\n",
    "- `Activation (activation)`: activation function name (`relu`, `gelu`, `tanh`, `sigmoid`, `leakyrelu`, `elu`).\n",
    "- `Dropout (dropout)`: dropout probability applied after activations (0 disables).\n",
    "- `Optimizer (optimizer)`: optimizer choice (`adam`, `adamw`, `sgd`, `lm`; `lm` uses an LBFGS-based Levenberg–Marquardt-like step and ignores schedulers).\n",
    "- `Learning Rate (lr)`: learning rate supplied to the optimizer (default 1e-3).\n",
    "- `Batch Normalization (batchnorm)`: enable per-layer batch normalization (`True`/`False`).\n",
    "- `Residual Layers (residual)`: add skip connections when layer dimensions align (`True`/`False`).\n",
    "- `Scheduler (scheduler)`: toggle StepLR scheduler usage (`True`/`False`).\n",
    "- `Scheduler Step Size (step_size)`: StepLR step interval in epochs when scheduler is active (default 3).\n",
    "- `Epochs (epochs)`: total training epochs (default 5).\n",
    "- `Batch Size (batch_size)`: mini-batch size used by data loaders (default 128).\n",
    "- `Error Metric ()`: Error metric used for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c381f7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437aae336a5e4606be73815336897cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(GridBox(children=(BoundedIntText(value=4, description='Number of Layers', layout=Layout(flex='1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if WIDGETS_AVAILABLE:\n",
    "    try:\n",
    "        # Attach handler only if not attached already (idempotent)\n",
    "        if 'run_button' in globals():\n",
    "            if not getattr(run_button, '_on_run_attached', False):\n",
    "                run_button.on_click(on_run)\n",
    "                run_button._on_run_attached = True\n",
    "        display(container)\n",
    "    except Exception as e:\n",
    "        print('Error while attaching run handler / displaying GUI:', e)\n",
    "else:\n",
    "    print(\"ipywidgets not available. Use manual config in next cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "80def55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437aae336a5e4606be73815336897cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(GridBox(children=(BoundedIntText(value=4, description='Number of Layers', layout=Layout(flex='1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Re-display GUI and attach handlers if needed (safe to run multiple times)\n",
    "if WIDGETS_AVAILABLE:\n",
    "    try:\n",
    "        # Re-attach handler only once to avoid duplicated events\n",
    "        if 'run_button' in globals():\n",
    "            if not getattr(run_button, '_on_run_attached', False):\n",
    "                run_button.on_click(on_run)\n",
    "                run_button._on_run_attached = True\n",
    "        # Some users may want to re-display the main container if the frontend cleared it\n",
    "        if 'container' in globals():\n",
    "            display(container)\n",
    "        else:\n",
    "            print('Container not available; re-run GUI setup cell to (re)create widgets.')\n",
    "    except Exception as e:\n",
    "        print('Error while (re)attaching GUI:', e)\n",
    "else:\n",
    "    print('ipywidgets unavailable; cannot display GUI.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac82fb5",
   "metadata": {},
   "source": [
    "### If no GUI, configure by modifying code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "550821f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training run on MNIST\n",
    "example_cfg = RunConfig(\n",
    "    depth=4,\n",
    "    hidden_width=256,\n",
    "    activation=\"relu\",\n",
    "    dropout=0.1,\n",
    "    batchnorm=True,\n",
    "    residual=True,\n",
    "    optimizer=\"adam\",\n",
    "    lr=1e-3,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    scheduler=False,\n",
    ")\n",
    "# Uncomment below to run the example configuration\n",
    "# print('Launching example configuration:', example_cfg)\n",
    "# example_model, example_history = run_experiment(example_cfg)\n",
    "# plot_history(\n",
    "#     example_history,\n",
    "#     title=f\"Example Run (activation={example_cfg.activation}, depth={example_cfg.depth}, width={example_cfg.hidden_width})\"\n",
    "# )\n",
    "# plot_run_log('test_error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
